{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "v6Vrr3322FTN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In class, we attempted to create by hand a neural network that computes the XOR function. If this was possible, see if you can simplify the network we built. If it was not possible, give a full explanation why it canâ€™t be done."
      ]
    },
    {
      "metadata": {
        "id": "rJfQmPsV2KOc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This was possible if we used a non-linear activation function in our hidden layer, consisting of two nodes, and a linear activation function in our output layer, consisting of one node. I don't believe we can simplify the network. The reason I believe this is because at minimum, you need an single node for output to say whether or not the answer is a zero or one. Also, if you look at a plot of xor, you will see that the two answers you need can not be sperated by one single line, since that line would include an incorrect answer. So, to solve this problem, imagine the answer is written on a square. The top left and the bottom right corners have the right answers, and the other corners do not. If you fold up the two \"correct\" corners together, therefore folding the square into a triangle, you can now see a clear seperation between the right and the wrong answers. However, in order to do this we needed to at least one corner in two dimentions (because we need to move it up/down and left/right, which requires two nodes), and in a nonlinear fashion (since we're deforming space, which requires a non-linear activation function). So, I believe the simplest network is the one stated above."
      ]
    },
    {
      "metadata": {
        "id": "03ssME-Ko7Kr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use Python/NumPy/Pandas/Keras to load and manipulate the Boston Housing Dataset as follows."
      ]
    },
    {
      "metadata": {
        "id": "l40EiRmBqtoI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "\n",
        "# read more about the data here: https://www.kaggle.com/c/boston-housing\n",
        "boston_housing_df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\", sep = \",\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GvjBHqE0qYHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compute the dimensions of the data structures. Include code to print these values."
      ]
    },
    {
      "metadata": {
        "id": "PGZgyAl-qbm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "195a9658-8211-47a1-8065-0870567a6ac9"
      },
      "cell_type": "code",
      "source": [
        "def print_structure():\n",
        "    print(\n",
        "        \"Boston housing dataset \\\n",
        "            \\n\\tcount: %s \\\n",
        "            \\n\\tdimensions: %s \\\n",
        "            \\n\\tshape: %s \\n\\n\" % (len(boston_housing_df), boston_housing_df.ndim, boston_housing_df.shape)\n",
        "    )\n",
        "\n",
        "\n",
        "print_structure()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Boston housing dataset             \n",
            "\tcount: 506             \n",
            "\tdimensions: 2             \n",
            "\tshape: (506, 14) \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z8McT5AzqcPC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Construct a suitable testing set, training set, and validation set for this data. Submit code to create these datasets but do not include the datasets themselves."
      ]
    },
    {
      "metadata": {
        "id": "Kd712tPWqeoC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "boston_housing_df = boston_housing_df.reindex(\n",
        "    np.random.permutation(boston_housing_df.index))\n",
        "\n",
        "training = boston_housing_df.head(430)\n",
        "testing = boston_housing_df.tail(76)\n",
        "\n",
        "training_examples = training.head(370)[[\n",
        "    \"crim\",\n",
        "    \"zn\",\n",
        "    \"indus\",\n",
        "    \"chas\",\n",
        "    \"nox\",\n",
        "    \"rm\",\n",
        "    \"age\",\n",
        "    \"dis\",\n",
        "    \"rad\",\n",
        "    \"tax\",\n",
        "    \"ptratio\",\n",
        "    \"b\",\n",
        "    \"lstat\"\n",
        "]].copy()\n",
        "training_targets = training.head(370)[\"medv\"].copy()\n",
        "\n",
        "validation_examples = training.tail(60)[[\n",
        "    \"crim\",\n",
        "    \"zn\",\n",
        "    \"indus\",\n",
        "    \"chas\",\n",
        "    \"nox\",\n",
        "    \"rm\",\n",
        "    \"age\",\n",
        "    \"dis\",\n",
        "    \"rad\",\n",
        "    \"tax\",\n",
        "    \"ptratio\",\n",
        "    \"b\",\n",
        "    \"lstat\"\n",
        "]].copy()\n",
        "validation_targets = training.tail(60)[\"medv\"].copy()\n",
        "\n",
        "testing_examples = testing[[\n",
        "    \"crim\",\n",
        "    \"zn\",\n",
        "    \"indus\",\n",
        "    \"chas\",\n",
        "    \"nox\",\n",
        "    \"rm\",\n",
        "    \"age\",\n",
        "    \"dis\",\n",
        "    \"rad\",\n",
        "    \"tax\",\n",
        "    \"ptratio\",\n",
        "    \"b\",\n",
        "    \"lstat\"\n",
        "]].copy()\n",
        "testing_targets = testing[\"medv\"].copy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dor_xw01qe_i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create one new synthetic feature that could be useful for machine learning in this domain. Explain what it is and why it might be useful."
      ]
    },
    {
      "metadata": {
        "id": "ClMW5qK6qiEy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This feature could be useful because it will give a big number if there are large houses nearer to employment zones.\n",
        "# Typically large houses near business zones (where land tends to be expensive) cost more I believe.\n",
        "boston_housing_df[\"large_homes_near_business\"] = (\n",
        "    boston_housing_df[\"zn\"] / boston_housing_df[\"dis\"])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}